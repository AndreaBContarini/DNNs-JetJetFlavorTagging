# -*- coding: utf-8 -*-
"""F-F.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b0fFayhDfmDJHlJMH5M5goC27ocgvHLr

#1. Librerie & dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torchvision
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader, Dataset
from torch import nn
import torch.nn.functional as F
from torch import optim
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
import itertools

!pip install torchmetrics
!pip install torchsummary

"""##Caricamento Dataset"""

#Dataset
!rm -rf Dataset_numpy.npz
!gdown 19Qu3CfGdsaV70U-WMTRQS3GGCH-lN7SR

"""##Trattamento dati (shuffle)"""

N = int(4E6)

dataset = np.load('Dataset_numpy.npz')
tmp_X = dataset['X'].reshape(int(11E6),16)
tmp_y = dataset['y'].reshape(int(11E6),1)

Xy=np.append(tmp_X, tmp_y, axis=1)

print(np.shape(Xy))

"""**Schuffle**"""

np.random.shuffle(Xy)

X_fin=Xy[:,:16]
y_fin=Xy[:,16]
print(np.shape(X_fin))
print(np.shape(y_fin))

X=X_fin[:N]
y=y_fin[:N]
print(np.shape(X))
print(np.shape(y))

"""**GPU**"""

if torch.cuda.is_available():
  print('Numero di GPU disponibili: ',torch.cuda.device_count())
  for i in range(0,torch.cuda.device_count()):
    print(torch.cuda.get_device_name(i))

# se la GPU è disponibile setto device='cuda', altrimenti 'cpu
device = ('cuda' if torch.cuda.is_available() else 'cpu') # Tramite questo oggetto si realizzerà lo spostamento
print("Computation device:", device, "\n")

"""#2. **Feed-Forward model**

##Generazione classe dataset
"""

class myDataset(Dataset):
    def __init__(self, data, labels):
        super(myDataset, self).__init__()
        self.y = torch.tensor(labels).float()
        self.X = torch.tensor(data).float()

    def __len__(self):
        return self.X.shape[0]

    # il metodo __getitem__ implementa la logica del dataset
    def __getitem__(self, i):
       outx = self.X[i]
       outy = self.y[i]
       return outx, outy

"""##SPLITTING train/validation/test

"""

a=int(N*0.8)
b=int(N*0.1)
c=N-a-b


X_train, X_med, y_train, y_med = train_test_split(X, y, test_size = b+c)
X_vali, X_test, y_vali, y_test = train_test_split(X_med, y_med, test_size = c)

mean = np.mean(X_train, axis = 0)
stddev = np.std(X_train, axis = 0)

X_train_norm = (X_train-mean)/stddev
X_vali_norm = (X_vali-mean)/stddev
X_test_norm = (X_test-mean)/stddev

print(np.mean(X_train_norm, axis=0))
print(np.std(X_train_norm, axis=0))

print(np.mean(X_vali_norm, axis=0))
print(np.std(X_vali_norm, axis=0))

print(np.mean(X_vali_norm, axis=0))
print(np.std(X_vali_norm, axis=0))

print(np.shape(X_train_norm))

train_dataset = myDataset(
    data = X_train_norm,
    labels = y_train
)
vali_dataset = myDataset(
    data = X_vali_norm,
    labels = y_vali
)
test_dataset = myDataset(
    data = X_test_norm,
    labels = y_test
)

"""##Dataloaders"""

batch_size = 300
train_loader = DataLoader(train_dataset,
                          batch_size=batch_size,
                          shuffle=True, drop_last=True)

vali_loader = DataLoader(vali_dataset,
                         batch_size=batch_size,
                         shuffle=True, drop_last=True)

test_loader = DataLoader(test_dataset,
                         batch_size=batch_size,
                         shuffle=True, drop_last=True)

x, y = next(iter(train_loader))

print(x)
print(x.shape)

"""##**Definizione della F-F**"""

class Feed_Forward(nn.Module):
  def __init__(self, input_dim=16, output_dim=2, l1=2048, l2=1024, l3=512, l4=256, l5=64, pdrop=0.0):
    super(Feed_Forward, self).__init__()

    self.layer1 = nn.Linear(input_dim, l1)
    nn.init.xavier_uniform_(self.layer1.weight)
    self.drop1 = nn.Dropout(p=pdrop)
    self.layer2 = nn.Linear(l1, l1)
    nn.init.xavier_uniform_(self.layer2.weight)
    self.drop2 = nn.Dropout(p=pdrop)
    self.layer3 = nn.Linear(l1, l2)
    nn.init.xavier_uniform_(self.layer3.weight)
    self.drop3 = nn.Dropout(p=pdrop)
    self.layer4 = nn.Linear(l2, l2)
    nn.init.xavier_uniform_(self.layer4.weight)
    self.drop4 = nn.Dropout(p=pdrop)
    self.layer5 = nn.Linear(l2, l3)
    nn.init.xavier_uniform_(self.layer5.weight)
    self.drop5 = nn.Dropout(p=pdrop)
    self.layer6 = nn.Linear(l3, l3)
    nn.init.xavier_uniform_(self.layer6.weight)
    self.drop6 = nn.Dropout(p=pdrop)
    self.layer7 = nn.Linear(l3, l4)
    nn.init.xavier_uniform_(self.layer7.weight)
    self.drop7 = nn.Dropout(p=pdrop)
    self.layer8 = nn.Linear(l4, l4)
    nn.init.xavier_uniform_(self.layer8.weight)
    self.drop8 = nn.Dropout(p=pdrop)
    self.layer9 = nn.Linear(l4, l5)
    nn.init.xavier_uniform_(self.layer9.weight)
    self.drop9 = nn.Dropout(p=pdrop)
    self.layer10 = nn.Linear(l5, l5)
    nn.init.xavier_uniform_(self.layer10.weight)
    self.layer11 = nn.Linear(l5, output_dim)
    nn.init.uniform_(self.layer11.weight, a=-0.05, b=0.05)

  def forward(self, x):
    x = self.layer1(x)
    x = F.relu(x)
    x = self.drop1(x)
    x = self.layer2(x)
    x = F.relu(x)
    x = self.drop2(x)
    x = self.layer3(x)
    x = F.relu(x)
    x = self.drop3(x)
    x = self.layer4(x)
    x = F.relu(x)
    x = self.drop4(x)
    x = self.layer5(x)
    x = F.relu(x)
    x = self.drop5(x)
    x = F.relu(x)
    x = self.layer6(x)
    x = F.relu(x)
    x = self.drop6(x)
    x = self.layer7(x)
    x = F.relu(x)
    x = self.drop7(x)
    x = self.layer8(x)
    x = F.relu(x)
    x = self.drop8(x)
    x = self.layer9(x)
    x = F.relu(x)
    x = self.drop9(x)
    x = self.layer10(x)
    x = F.relu(x)
    x = self.layer11(x)
    out = F.log_softmax(x, dim=1)
    return out

"""#3. Sommario"""

model = Feed_Forward(l1=4096, l2=2048, l3=1024, l4=512, l5=64, pdrop=0.0)
print(model)

from torchsummary import summary
if torch.cuda.is_available():
  summary(model.cuda(), input_size=(1,16))
else:
  summary(model, input_size=(1,16))

"""##CHECK FUNZIONAMENTO RETE"""

feat, label = next(iter(train_loader))

feat=feat.to(device)
label=label.to(device)

out = model(feat)

print(out.shape)
print(out[0])

prob = torch.exp(out[0])
print(prob)

"""Definizione della metrica, dell'ottimizzatore e di uno scheduler per il learning rate:"""

from torchmetrics import AUROC

loss_func = nn.CrossEntropyLoss()

metric_func = AUROC(num_classes=2)
from torch import optim
LR_ST = 2E-3

opt = optim.SGD(model.parameters(), lr = LR_ST, momentum = 0.9)

scheduler = optim.lr_scheduler.StepLR(opt, 50, gamma=0.05, last_epoch=-1, verbose=True)

epochs_done = 0

model.to(device)
print(next(model.parameters()).device)

"""### Best and last model da salvare"""

class SaveBestModel: # Ad ogni epoca si controlla se il modello è migliorato; in caso, lo si salva
  def __init__(self, best_valid_loss = float('inf')): #object initialized with best_loss = +infinite. In questo modo si è sicuri che anche solo la prima epoca verrà salvata
      self.best_valid_loss = best_valid_loss


  def __call__(
      self, current_valid_loss,
      epoch, model, optimizer, criterion, metric,
  ):
      if current_valid_loss < self.best_valid_loss:
         self.best_valid_loss = current_valid_loss
         torch.save({'model' : model,
                'epoch': epoch+1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': criterion,
                'metric': metric,
                'best validation loss': current_valid_loss,
                }, 'best_model.pt') # Si crea un dizionario per aver ulteriori informazioni sul modello che è stato salvato. Vanno bene sia i formati pt, sia pth


class SaveLastModel:
  def __init__(self, dummy=0):
        self.dummy = 0

  def __call__(
      self,current_vali_loss, epoch, model, optimizer_state_dict, criterion, metric, scheduler, optimizer):
      torch.save({'model' : model,
                'epoch': epoch+1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': criterion,
                'metric': metric,
                'vali loss': current_vali_loss,
                'scheduler': scheduler,
                'optimizer': optimizer,
                }, 'last_model.pt') # Si crea un dizionario per aver ulteriori informazioni sul modello che è stato salvato. Vanno bene sia i formati pt, sia pth

"""#4. **Training**"""

# Commented out IPython magic to ensure Python compatibility.
import time

save_best_model = SaveBestModel()
save_last_model = SaveLastModel()

# numero di epoche
epochs = 50-epochs_done


# liste su cui salvare il valore della loss e della metrica ad ogni epoca per poterli graficare a fine addestramento
hist_loss = []
hist_metric = []
hist_vloss = []
hist_vmetric = []


for epoch in range(epochs):
    t0 = time.time()

    # training step, in cui aggiorno i pesi della rete
    model.train()
    train_loss = 0
    train_metric = 0
    counter = 0
    for xb, yb in train_loader:
        counter += 1

        yb=yb.type(torch.LongTensor) # Casting necessario(cfr. specifiche CrossEntropy)

        xb=xb.to(device)
        yb=yb.to(device).view(batch_size)

        pred = model(xb)

        # calcolo loss e metrica
        loss = loss_func(pred, yb)
        prob_pred = torch.exp(pred)
        metric = metric_func(prob_pred, yb)

        # aggiorno la loss e metrica totale
        train_loss += loss.item()
        train_metric += metric.item()

        # backpropagation
        opt.zero_grad() #resetta i gradienti prima di eseguire la backpropagation
        loss.backward() #calcola i gradeinti della loss
        opt.step() #aggiorna i pesi

        # RESET METRICHE

        metric_func.reset()

    train_loss /= counter
    train_metric /= (counter)
    hist_loss.append(train_loss)
    hist_metric.append(train_metric)

    #Validation step (non aggiornato i pesi)
    model.eval()
    vali_loss = 0
    vali_metric = 0
    counter = 0
    with torch.no_grad(): #evita che si aggiornino i pesi
      for xb, yb in vali_loader:
        counter += 1

        yb=yb.type(torch.LongTensor)

        xb=xb.to(device)
        yb=yb.to(device).view(batch_size)

        pred = model(xb) #predizione del modello

        # calcolo loss e metrica
        vloss = loss_func(pred, yb)

        prob_pred = torch.exp(pred)
        vmetric = metric_func(prob_pred, yb)

        vali_loss += vloss.item()
        vali_metric += vmetric.item()

        # RESET DELLE METRICHE

        metric_func.reset()

    vali_loss /= counter
    vali_metric /= (counter)
    hist_vloss.append(vali_loss)
    hist_vmetric.append(vali_metric)

    #save best model
    save_best_model(vali_loss, epoch, model, opt, loss_func, metric_func)

    elapsed_time = time.time()-t0
    print("epoch: %d, time(s): %.4f, train loss: %.6f, train metric: %.6f, vali loss: %.6f, vali metric: %.6f"
#           % (epoch+1+epochs_done, elapsed_time, train_loss, train_metric, vali_loss, vali_metric))

    scheduler.step()

    #save last model
    save_last_model(vali_loss, epoch+epochs_done, model, opt, loss_func, metric_func, scheduler, opt)

"""#5. **PARTE DI PLOT**"""

plt.figure(figsize=(14,7))
plt.subplot(1,2,1)

plt.title('ANDAMENTO DELLA METRICA')
plt.plot(range(1,len(hist_vmetric)+1), hist_vmetric, '-o', label='Validation', color='green')
plt.plot(range(1,len(hist_metric)+1), hist_metric, '-o', label='Train',color='red')

plt.xlabel("Epoca")
plt.ylabel("AUC (metrica)")
plt.legend()
plt.grid()

plt.subplot(1,2,2)
plt.title('ANDAMENTO DELLA LOSS')
plt.plot(range(1,len(hist_vloss)+1), hist_vloss, '-o', label='Validation',color='green')
plt.plot(range(1,len(hist_loss)+1), hist_loss, '-o', label='Train',color='red')
plt.xlabel("Epoca")
plt.ylabel("CrossEntropyLoss")
plt.legend()
plt.grid()

plt.tight_layout()
plt.savefig('FF_Loss_and_Metric.pdf', format='pdf')

plt.tight_layout()
plt.show()

"""#6. **Test:**

Si prende per il test il best model
"""

model = torch.load('./best_model.pt')
torch.save(model, './trained_model.pt')

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import roc_curve

plt.figure(figsize=(8,8))

model = torch.load('./trained_model.pt')
model.eval()
#the eval() function is used to evaluate the train model.
#model.eval() is a kind of switch for some specific layers/parts of the model,
#that behave differently during training and evaluating time

test_loss = 0
test_metric = 0
counter = 0


megapred = []
megatarget = []
megapred = np.array(megapred)
megatarget = np.array(megatarget)

model.to(torch.device('cpu'))

for xb, yb in test_loader:
  counter += 1

  yb=yb.type(torch.LongTensor)

  xb=xb.to('cpu')
  yb=yb.to('cpu').view(batch_size)

  pred = model(xb)

  tloss = loss_func(pred, yb)

  prob_pred = torch.exp(pred)
  prob_positive = prob_pred[:,1].detach().numpy()
  tmetric = metric_func(prob_pred, yb)

  batch_target = yb.numpy()

  megapred = np.append(megapred, prob_positive)
  megatarget = np.append(megatarget, batch_target)

  test_loss += tloss.item()
  test_metric += tmetric.item()

  metric_func.reset()

test_loss /= counter
test_metric /= (counter)

fpr, tpr, thresholds = roc_curve(megatarget, megapred, pos_label=1)
plt.plot(fpr,tpr,'blue')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('Feed Forward Test Set')
plt.xlim(0,1)
plt.plot([0,1],[0,1],'--k')
plt.ylim(0,1)
plt.tight_layout
plt.show()

print("test loss: %.6f, test metric: %.6f"
#           % (test_loss, test_metric))

"""##**Confuison Matrix**"""

from sklearn.metrics import confusion_matrix

predictions = []

for i in range(len(megapred)):
  if megapred[i]<=0.5:
    predictions.append(0)
  else:
    predictions.append(1)

predictions = np.array(predictions)

conf_m = confusion_matrix(megatarget, predictions)
conf_m = conf_m.astype('float') / conf_m.sum(axis=1)[:, np.newaxis]
fig = plt.figure(figsize = (12,12))
ax = fig.add_subplot(111)
ax.imshow(conf_m, cmap ='gray')
thresh = conf_m.max()/2.5
ax.axis('off')
plt.title('Matrice di Confusione FF (Dataset normale)',fontsize='xx-large')
for x in range(2):
    for y in range(2):
        val = round(conf_m[x][y],5) if conf_m[x][y] !=0 else 0
        ax.annotate(str(val), xy=(y,x),
                    horizontalalignment='center',
                    verticalalignment='center',
                    color='white' if conf_m[x][y]<thresh else 'black',
                    fontsize='xx-large')

plt.tight_layout()
plt.show()